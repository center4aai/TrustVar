# src/adapters/ollama_adapter.py
import json
from typing import List

import aiohttp

from src.adapters.base import BaseLLMAdapter
from src.config.settings import get_settings
from src.utils.logger import logger

settings = get_settings()


class OllamaAdapter(BaseLLMAdapter):
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è Ollama"""

    def __init__(self, model):
        super().__init__(model)
        self.base_url = settings.OLLAMA_BASE_URL

    async def download_model(self) -> bool:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å Ollama —á–µ—Ä–µ–∑ –µ—ë REST API.

        Args:
            model_name (str): –ò–º—è –º–æ–¥–µ–ª–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä "llama3", "mistral", "phi3".
            host (str): –ê–¥—Ä–µ—Å —Å–µ—Ä–≤–µ—Ä–∞ Ollama (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ª–æ–∫–∞–ª—å–Ω—ã–π).

        Returns:
            bool: True ‚Äî –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–∞, –∏–Ω–∞—á–µ False.
        """
        url = f"{self.base_url}/api/pull"
        payload = {
            "name": self.model.model_name,
            "stream": True,  # –í–∞–∂–Ω–æ: Ollama –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ç–æ–∫ —Å–æ–±—ã—Ç–∏–π
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload) as response:
                    if response.status != 200:
                        logger.error(
                            f"‚ùå –û—à–∏–±–∫–∞: —Å–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status}"
                        )
                        return False

                    async for line in response.content:
                        if not line.strip():
                            continue
                        try:
                            event = json.loads(line.decode("utf-8"))
                        except json.JSONDecodeError:
                            continue

                        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç—É—Å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                        if "status" in event:
                            logger.info(f"üì• {event['status']}")

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
                        if event.get("status") == "success":
                            logger.info(
                                f"‚úÖ –ú–æ–¥–µ–ª—å '{self.model.model_name}' —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–∞!"
                            )
                            return True

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫—É
                        if "error" in event:
                            logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {event['error']}")
                            return False

            # –ï—Å–ª–∏ —Ü–∏–∫–ª –∑–∞–≤–µ—Ä—à–∏–ª—Å—è, –Ω–æ success –Ω–µ –ø—Ä–∏—à—ë–ª
            logger.info("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –Ω–æ —Å—Ç–∞—Ç—É—Å 'success' –Ω–µ –ø–æ–ª—É—á–µ–Ω.")
            return False

        except aiohttp.ClientConnectorError:
            logger.error(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É Ollama. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –∑–∞–ø—É—â–µ–Ω: `ollama serve`"
            )
            return False
        except Exception as e:
            logger.error(f"üö® –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return False

    async def generate(self, prompt: str, **kwargs) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Ollama API"""
        url = f"{self.base_url}/api/generate"

        payload = {
            "model": self.model.model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": kwargs.get("temperature", self.config.temperature),
                "top_p": kwargs.get("top_p", self.config.top_p),
                "top_k": kwargs.get("top_k", self.config.top_k),
                "num_predict": kwargs.get("max_tokens", self.config.max_tokens),
                "repeat_penalty": self.config.repeat_penalty,
                "stop": self.config.stop_sequences,
            },
        }

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, timeout=300) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result.get("response", "")
                    else:
                        error = await response.text()
                        logger.error(f"Ollama API error: {error}")
                        raise Exception(f"Ollama API error: {response.status}")
        except Exception as e:
            logger.error(f"Error generating with Ollama: {e}")
            raise

    async def batch_generate(self, prompts: List[str], **kwargs) -> List[str]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è"""
        import asyncio

        tasks = [self.generate(prompt, **kwargs) for prompt in prompts]
        return await asyncio.gather(*tasks)

    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama"""
        try:
            url = f"{self.base_url}/api/tags"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=5) as response:
                    if response.status == 200:
                        data = await response.json()
                        models = [m["name"] for m in data.get("models", [])]
                        return self.model.model_name in models
            return False
        except:
            return False
