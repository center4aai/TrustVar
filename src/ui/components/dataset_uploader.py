# src/ui/components/dataset_uploader.py
import csv
import io
import json
from pathlib import Path

import streamlit as st
from requests.exceptions import RequestException

from src.config.constants import SUPPORTED_TASKS
from src.ui.api_client import ApiClient


class DatasetUploader:
    def __init__(self, api_client: ApiClient):
        self.api_client = api_client

    def _detect_format_from_file(self, file) -> str:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É"""
        filename = file.name
        ext = Path(filename).suffix.lower()

        # –ü—Ä–æ—Å—Ç—ã–µ —Å–ª—É—á–∞–∏ - –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
        if ext == ".csv":
            return "csv"
        elif ext == ".parquet":
            return "parquet"
        elif ext == ".jsonl":
            return "jsonl"
        elif ext == ".json":
            return self._detect_json_format(file)

        return "json"

    def _detect_json_format(self, file) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ JSON —Ñ–∞–π–ª –æ–±—ã—á–Ω—ã–º JSON –∏–ª–∏ JSONL"""
        try:
            file.seek(0)
            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–∞–π—Ç
            first_line = file.readline().decode("utf-8").strip()
            file.seek(0)

            # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å '[' - —ç—Ç–æ JSON array
            if first_line.startswith("["):
                return "json"

            # –ï—Å–ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –≤–∞–ª–∏–¥–Ω—ã–π JSON –æ–±—ä–µ–∫—Ç (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å '{')
            if first_line.startswith("{"):
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ–º –ª–∏ –º—ã —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –æ–±—ä–µ–∫—Ç
                    json.loads(first_line)

                    # –ß–∏—Ç–∞–µ–º –≤—Ç–æ—Ä—É—é —Å—Ç—Ä–æ–∫—É
                    file.seek(0)
                    file.readline()  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é
                    second_line = file.readline().decode("utf-8").strip()
                    file.seek(0)

                    # –ï—Å–ª–∏ –µ—Å—Ç—å –≤—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ –∏ –æ–Ω–∞ —Ç–æ–∂–µ JSON –æ–±—ä–µ–∫—Ç - —ç—Ç–æ JSONL
                    if second_line and second_line.startswith("{"):
                        try:
                            json.loads(second_line)
                            return "jsonl"
                        except:
                            pass

                    # –ò–Ω–∞—á–µ –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –≤–µ—Å—å —Ñ–∞–π–ª –∫–∞–∫ JSON
                    content = file.read().decode("utf-8")
                    file.seek(0)
                    json.loads(content)
                    return "json"

                except json.JSONDecodeError:
                    pass

        except Exception:
            pass
        finally:
            file.seek(0)

        return "json"

    def render(self):
        st.markdown("### ‚ûï Upload New Dataset")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –Ω–µ–¥–∞–≤–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç
        if "upload_success_message" in st.session_state:
            st.success(st.session_state.upload_success_message)
            st.balloons()
            del st.session_state.upload_success_message

            col1, col2 = st.columns(2)
            with col1:
                if st.button("üìã View All Datasets", type="primary", width="stretch"):
                    st.session_state.active_dataset_tab = 0
                    st.rerun()
            with col2:
                if st.button("‚ûï Upload Another", width="stretch"):
                    st.rerun()

            st.markdown("---")

        # File uploader –í–ù–ï —Ñ–æ—Ä–º—ã
        st.markdown("**üìÅ Upload File**")

        uploaded_file = st.file_uploader(
            "Choose your dataset file",
            type=["jsonl", "json", "csv", "parquet"],
            help="Upload your dataset file (format will be detected automatically)",
            key="dataset_file_uploader",
        )

        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞ (–ª–æ–∫–∞–ª—å–Ω—ã–µ, –Ω–µ –≤ session_state)
        detected_format = None
        columns = []
        preview = []

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
        if uploaded_file is not None:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            detected_format = self._detect_format_from_file(uploaded_file)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª
            try:
                columns = self._extract_columns(uploaded_file, detected_format)
                preview = self._get_preview(uploaded_file, detected_format)
            except Exception as e:
                st.error(f"‚ùå Error analyzing file: {e}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
            col1, col2, col3 = st.columns([2, 1, 1])
            with col1:
                st.info(f"üìÑ **File:** {uploaded_file.name}")
            with col2:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –ø–æ—è—Å–Ω–µ–Ω–∏–µ–º –¥–ª—è JSON
                format_display = (
                    detected_format.upper() if detected_format else "Unknown"
                )
                if (
                    Path(uploaded_file.name).suffix.lower() == ".json"
                    and detected_format
                ):
                    if detected_format == "jsonl":
                        format_display = "JSONL (JSON Lines)"
                    else:
                        format_display = "JSON (Array)"
                st.success(f"**Format:** {format_display}")
            with col3:
                size_kb = uploaded_file.size / 1024
                size_str = (
                    f"{size_kb:.1f} KB"
                    if size_kb < 1024
                    else f"{size_kb / 1024:.1f} MB"
                )
                st.metric("Size", size_str)

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            if columns:
                st.success(
                    f"‚úÖ Found {len(columns)} columns: {', '.join(columns[:5])}{('...' if len(columns) > 5 else '')}"
                )
            else:
                st.warning("‚ö†Ô∏è No columns detected. Please check your file format.")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö (–≤–Ω–µ —Ñ–æ—Ä–º—ã –¥–ª—è –ª—É—á—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏)
        if preview:
            st.markdown("---")
            st.markdown("**üìä Data Preview**")
            import pandas as pd

            df_preview = pd.DataFrame(preview[:5])
            st.dataframe(df_preview, width="stretch", hide_index=True)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º expected format —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω
        if uploaded_file is None:
            st.markdown("---")
            st.markdown("**üí° Supported Formats & Examples**")

            tab1, tab2, tab3, tab4 = st.tabs(
                ["JSON Lines", "JSON Array", "CSV", "Parquet"]
            )

            with tab1:
                st.markdown("**JSON Lines format** (`.jsonl` or `.json`)")
                st.caption("Each line is a separate JSON object")
                st.code(
                    """{"prompt": "What is AI?", "target": "Artificial Intelligence..."}
{"prompt": "Explain ML", "target": "Machine Learning..."}""",
                    language="json",
                )

            with tab2:
                st.markdown("**JSON array format** (`.json`)")
                st.caption("Array of JSON objects")
                st.code(
                    """[
  {"prompt": "What is AI?", "target": "Artificial Intelligence..."},
  {"prompt": "Explain ML", "target": "Machine Learning..."}
]""",
                    language="json",
                )

            with tab3:
                st.markdown("**CSV format** (`.csv`)")
                st.caption("Comma-separated values with header")
                st.code(
                    '''prompt,target
"What is AI?","Artificial Intelligence..."
"Explain ML","Machine Learning..."''',
                    language="csv",
                )

            with tab4:
                st.markdown("**Parquet format** (`.parquet`)")
                st.info(
                    "Apache Parquet binary columnar format - efficient for large datasets"
                )

        st.markdown("---")

        # –§–æ—Ä–º–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–¥–µ—Å—å
        with st.form("upload_dataset_form", clear_on_submit=True):
            st.markdown("**üìù Dataset Information**")

            col1, col2 = st.columns(2)

            with col1:
                name = st.text_input(
                    "Dataset Name*",
                    placeholder="e.g., QA Test Set v1",
                    help="A unique name for your dataset",
                )

                task_type = st.selectbox(
                    "Task Type*",
                    SUPPORTED_TASKS,
                    help="The type of task this dataset is for",
                )

            with col2:
                description = st.text_area(
                    "Description",
                    placeholder="Brief description of the dataset...",
                    height=100,
                )

                tags = st.text_input(
                    "Tags (comma-separated)",
                    placeholder="e.g., qa, english, test",
                    help="Tags to help organize datasets",
                )

            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ (–µ—Å–ª–∏ —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω)
            if columns:
                st.markdown("---")
                st.markdown("**‚öôÔ∏è Column Mapping**")
                st.caption("Map your dataset columns to the required fields")

                col1, col2 = st.columns(2)

                with col1:
                    # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è prompt
                    prompt_default_idx = 0
                    prompt_candidates = ["prompt", "question", "input", "query", "text"]
                    for candidate in prompt_candidates:
                        if candidate in columns:
                            prompt_default_idx = columns.index(candidate)
                            break

                    prompt_column = st.selectbox(
                        "üéØ Prompt Column* (Required)",
                        options=columns,
                        index=prompt_default_idx,
                        help="Column containing the input prompts/questions",
                    )

                    # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è target
                    target_options = ["None"] + columns
                    target_default_idx = 0
                    target_candidates = [
                        "target",
                        "answer",
                        "output",
                        "response",
                        "completion",
                    ]
                    for candidate in target_candidates:
                        if candidate in columns:
                            target_default_idx = columns.index(candidate) + 1
                            break

                    target_column = st.selectbox(
                        "‚úì Target Column (Optional)",
                        options=target_options,
                        index=target_default_idx,
                        help="Column containing expected answers/outputs",
                    )

                    target_column_default_value = st.text_input(
                        "Default Target value (Optional)",
                        placeholder="e.g., '1' or '5' or any other text",
                    )

                with col2:
                    include_column = st.selectbox(
                        "‚ûï Include List Column (Optional)",
                        options=["None"] + columns,
                        help="Column with words that must appear in output",
                    )

                    exclude_column = st.selectbox(
                        "‚ûñ Exclude List Column (Optional)",
                        options=["None"] + columns,
                        help="Column with words that must NOT appear in output",
                    )

            else:
                prompt_column = "prompt"
                target_column = "None"
                include_column = "None"
                exclude_column = "None"

                if uploaded_file is None:
                    st.warning(
                        "üëÜ Please upload a file first to configure column mapping"
                    )
                else:
                    st.error(
                        "‚ö†Ô∏è Could not detect columns in the uploaded file. Please check the file format."
                    )

            # Submit button
            st.markdown("---")

            submitted = st.form_submit_button(
                "üöÄ Upload Dataset", type="primary", width="stretch"
            )

            if submitted:
                if not name:
                    st.error("‚ö†Ô∏è Please provide a dataset name")
                elif not uploaded_file:
                    st.error("‚ö†Ô∏è Please upload a file")
                elif not columns:
                    st.error("‚ö†Ô∏è Could not detect columns in the uploaded file")
                else:
                    try:
                        tag_str = (
                            ",".join([t.strip() for t in tags.split(",")])
                            if tags
                            else ""
                        )

                        with st.spinner("‚è≥ Uploading dataset..."):
                            result = self.api_client.create_dataset_and_upload(
                                name=name,
                                description=description,
                                task_type=task_type,
                                tags=tag_str,
                                file=uploaded_file,
                                file_format=detected_format,
                                prompt_column=prompt_column,
                                target_column=target_column
                                or str(target_column_default_value) + "_default",
                                include_column=None
                                if include_column == "None"
                                else include_column,
                                exclude_column=None
                                if exclude_column == "None"
                                else exclude_column,
                            )

                        count = result.get("items_uploaded", 0)

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—Ö–µ –∏ –æ—Å—Ç–∞–µ–º—Å—è –Ω–∞ –≤–∫–ª–∞–¥–∫–µ Upload
                        st.session_state.upload_success_message = f"‚úÖ Dataset '{name}' uploaded successfully with {count} items!"
                        st.session_state.active_dataset_tab = (
                            1  # –û—Å—Ç–∞–µ–º—Å—è –Ω–∞ Upload New
                        )

                        st.rerun()

                    except RequestException:
                        pass
                    except Exception as e:
                        st.error(f"‚ùå Error: {e}")

    def _extract_columns(self, file, file_format: str) -> list:
        """–ò–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
        file.seek(0)  # –°–±—Ä–æ—Å –ø–æ–∑–∏—Ü–∏–∏ —Ñ–∞–π–ª–∞

        try:
            if file_format == "jsonl":
                line = file.readline().decode("utf-8")
                if line.strip():
                    data = json.loads(line)
                    return list(data.keys())

            elif file_format == "json":
                content = file.read().decode("utf-8")
                data = json.loads(content)
                if isinstance(data, list) and len(data) > 0:
                    return list(data[0].keys())
                elif isinstance(data, dict):
                    items = data.get("data", data.get("items", []))
                    if items and len(items) > 0:
                        return list(items[0].keys())

            elif file_format == "csv":
                content = file.read().decode("utf-8")
                reader = csv.DictReader(io.StringIO(content))
                return list(reader.fieldnames) if reader.fieldnames else []

            elif file_format == "parquet":
                import pandas as pd

                df = pd.read_parquet(file)
                return df.columns.tolist()

        except Exception as e:
            raise Exception(f"Failed to extract columns: {str(e)}")
        finally:
            file.seek(0)  # –°–Ω–æ–≤–∞ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é

        return []

    def _get_preview(self, file, file_format: str, n_rows: int = 5) -> list:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö"""
        file.seek(0)

        try:
            if file_format == "jsonl":
                preview = []
                for i, line in enumerate(file):
                    if i >= n_rows:
                        break
                    line_str = line.decode("utf-8").strip()
                    if line_str:
                        data = json.loads(line_str)
                        preview.append(data)
                return preview

            elif file_format == "json":
                content = file.read().decode("utf-8")
                data = json.loads(content)
                if isinstance(data, list):
                    return data[:n_rows]
                elif isinstance(data, dict):
                    items = data.get("data", data.get("items", []))
                    return items[:n_rows]

            elif file_format == "csv":
                content = file.read().decode("utf-8")
                reader = csv.DictReader(io.StringIO(content))
                return [row for i, row in enumerate(reader) if i < n_rows]

            elif file_format == "parquet":
                import pandas as pd

                df = pd.read_parquet(file)
                return df.head(n_rows).to_dict("records")

        except Exception as e:
            raise Exception(f"Failed to generate preview: {str(e)}")
        finally:
            file.seek(0)

        return []
